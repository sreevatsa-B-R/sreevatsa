# Robots.txt for Sreevatsa B R Portfolio
# https://sreevatsa-b-r.github.io/sreevatsa/

# Allow all web crawlers
User-agent: *
Allow: /

# Specific rules for major search engines
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Bingbot
Allow: /
Crawl-delay: 1

User-agent: Slurp
Allow: /
Crawl-delay: 2

# Block AI training crawlers (optional)
User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: CCBot
Disallow: /

# Disallow common directories that shouldn't be indexed
Disallow: /node_modules/
Disallow: /.git/
Disallow: /dist/
Disallow: /build/
Disallow: /.vscode/
Disallow: /src/
Disallow: /server/

# Disallow specific file types
Disallow: *.json$
Disallow: *.js.map$
Disallow: *.css.map$
Disallow: /package*.json
Disallow: /vite.config.js
Disallow: /eslint.config.js

# Allow specific assets
Allow: /assets/
Allow: /public/
Allow: /*.css$
Allow: /*.js$
Allow: /*.png$
Allow: /*.jpg$
Allow: /*.jpeg$
Allow: /*.webp$
Allow: /*.svg$
Allow: /*.ico$

# Sitemap location
Sitemap: https://sreevatsa-b-r.github.io/sreevatsa/sitemap.xml

# Additional sitemaps for future use
# Sitemap: https://sreevatsa-b-r.github.io/sreevatsa/sitemap-images.xml
# Sitemap: https://sreevatsa-b-r.github.io/sreevatsa/sitemap-blog.xml

# Default crawl delay for other bots
User-agent: *
Crawl-delay: 5
